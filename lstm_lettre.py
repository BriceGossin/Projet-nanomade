import os
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.utils import to_categorical
from PyQt6.QtWidgets import QApplication, QFileDialog, QMessageBox

# üìÇ D√©finition du dossier contenant les donn√©es
DATASET_PATH = "Lettres/"
letters = sorted([d for d in os.listdir(DATASET_PATH) if os.path.isdir(os.path.join(DATASET_PATH, d))])

# üîπ Param√®tres
SEQUENCE_LENGTH = 50  # Nombre de lignes par s√©quence
FEATURES = 32  # Nombre total de colonnes utilis√©es (M_F_1 √† U_C_8)

X, Y = [], []
scaler = StandardScaler()

# üîç Fonction de chargement et nettoyage des donn√©es
def load_clean_data(file_path):
    try:
        df = pd.read_csv(file_path, header=0)
        df = df.iloc[:, 1:]  # Supprimer la colonne Timestamp
        df = df.apply(pd.to_numeric, errors='coerce').dropna()
        
        if len(df) >= SEQUENCE_LENGTH:
            df = df.iloc[:SEQUENCE_LENGTH]
        else:
            padding = np.zeros((SEQUENCE_LENGTH - len(df), FEATURES))
            df = np.vstack([df.values, padding])
        
        return df
    except Exception as e:
        print(f"Erreur lors du chargement de {file_path} : {e}")
        return None

# üîÑ Chargement des donn√©es
def load_dataset():
    for label, letter in enumerate(letters):
        letter_path = os.path.join(DATASET_PATH, letter)
        for file in os.listdir(letter_path):
            if not file.endswith(".csv"):  # Ignore les fichiers non CSV
                continue
            file_path = os.path.join(letter_path, file)
            cleaned_data = load_clean_data(file_path)
            if cleaned_data is not None:
                X.append(cleaned_data)
                Y.append(label)

load_dataset()

# Conversion en numpy arrays
X = np.array(X).astype(np.float32)
Y = to_categorical(Y, num_classes=len(letters))
X = scaler.fit_transform(X.reshape(-1, FEATURES)).reshape(-1, SEQUENCE_LENGTH, FEATURES)

print("‚úÖ Donn√©es charg√©es et pr√©trait√©es !")

# üî• D√©finition du mod√®le LSTM
model = Sequential([
    LSTM(64, activation='tanh', return_sequences=True, input_shape=(SEQUENCE_LENGTH, FEATURES)),
    Dropout(0.2),
    LSTM(32, activation='tanh'),
    Dropout(0.2),
    Dense(len(letters), activation='softmax')
])

# ‚öôÔ∏è Compilation du mod√®le
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# üèãÔ∏è Entra√Ænement du mod√®le
model.fit(X, Y, epochs=20, batch_size=16, validation_split=0.2)

# Sauvegarde du mod√®le
model.save("lstm_letter_recognition.h5")
print("‚úÖ Mod√®le entra√Æn√© et sauvegard√© !")

# Charger le mod√®le entra√Æn√©
model = tf.keras.models.load_model("lstm_letter_recognition.h5")

def predict_letter(file_path):
    data = load_clean_data(file_path)
    if data is None:
        return "Donn√©es invalides !"
    # Convertir en numpy array avant reshape
    data = data.to_numpy()  # Convertit le DataFrame en numpy.ndarray
    data = scaler.transform(data.reshape(-1, FEATURES)).reshape(-1, SEQUENCE_LENGTH, FEATURES)

    data = np.array(data).reshape(-1, SEQUENCE_LENGTH, FEATURES)  # Assurez-vous que SEQUENCE_LENGTH et FEATURES sont bien d√©finis
    prediction = model.predict(data)

    predicted_letter = letters[np.argmax(prediction)]
    return f"üî† Lettre pr√©dite : {predicted_letter}"

# üñ•Ô∏è Interface graphique Qt
app = QApplication([])
def open_file_dialog():
    file_path, _ = QFileDialog.getOpenFileName(None, "S√©lectionner un fichier CSV", "", "CSV Files (*.csv)")
    if file_path:
        prediction = predict_letter(file_path)
        QMessageBox.information(None, "R√©sultat de la pr√©diction", prediction)

open_file_dialog()
app.exec()